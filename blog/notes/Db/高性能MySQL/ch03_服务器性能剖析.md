Title: 3.1性能优化简介
Date:  2015-01-01


3.1性能优化简介
============================

我们将性能定义为：为完成某任务所需要的时间度量，性能即响应时间，这是一个非常重要的原则。我们通过任务和时间来度量性能，而不是资源；单位是每个查询花费的时间。

如果你认为，性能优化是降低CPU利用率，减少对资源的使用，那么这是一个陷阱。资源是用来消耗并用来工作的，所以有时消耗更多的资源能够加快查询速度。新版本的myql CPU利用率上升很利害，反而是对资源的利用率上升了。

呑吐量的提升只是性能优化的副产品，如果我们的目标是降低响应时间，先要搞清楚时间花在哪里。优化的第二个原则：无法测量就无法有效优化。

###3.1.1 通过性能剖析进行优化
* profiling
* Percona Toolkit中的pt-query-digest (maatkit mk-query-digest)
  Percona 提供了更多的查询级别的测量点 
  Percona 5.0 的慢查询日志，揭露了更多性能低下的原因，如磁盘IO、Waits、Row Lock Wait等。
 
###3.1.2 理解性能剖析
* 值得优化的查询： 1、占总比重很小的查询不值得优化。2、如果优化的成本大于收益，应当停止优化。
* 异常情况：某些任务即使没出现在性能剖析的前面，但每次执行缓慢，影响用户体验的，也需优化。
* 未知的未知： 工具的局限性。好的工具应该显示可能的丢失时间，这样才不会错过重要信息。
* 被掩盖的细节：性能剖析无法显示所有响应时间分布，所有病人的平均值没有任何价值。


##3.2对应用程序进行性能剖析
New Relic 服务，

### 3.2.1测试PHP应用程序
* xhprof
* xdebug、valgrind、cachegrind(开销较大)
* IfP (instrumentation-for-php)，http://code.google.com/p/instrumentation-for-php，该工具并不像xhporf对PHP做深入测量，而是现关注数据库调用，用于剖析数据库利用率。require('Instrumentation.php');Instrumentation::get_instance()->start_request();

   Ifp的结果很容易分析，pt-query-digest能够方便地从查询注释中抽取出键值对，所以只需要简单地将查询记录到MySQL日志文件中，对日志进行处理即可。
   Apache的mod_log_config模块也可以利用Ifp输出环境变量来定制日志输出，其它的%D宏可以记录微秒级请求。

* MySQL Enterprise Monitor也是值得考虑的工具之一。
* 代理层实现剖析，如mysql proxy。 

## 3.3 剖析MySQL查询
通过性能剖析，定位到具体需要优化的查询后，也可以对这些查询进行单独剖析，分析哪些子任务是响应时间的主要消耗者。

### 3.3.1 剖析服务器负载
定位和优化坏的查询，能够显著地提升应用的性能，也能解决某些特定的难题,还可以降低服务的整体压力。如果只需要剖析并找出代价高的查询，就不需要如此复杂，慢查询日志足矣。

#### 捕获MySQL的查询到日志文件中

慢查询日志最初只能捕获“慢”的查询，而性能剖析却需要针对所有的查询。MySQL5.0前的版本，慢查询日志的响应时间的单位是秒，粒度太粗，幸运的这些已经成为历史。MySQL5.0之后的版本中，功能增加，可以通过设置long_query_time=0来捕获所有的查询。Percona提供了更多对日志内容和查询捕获的更多控制能力。

在当前版本的MySQL中，慢查询日志是开销最低，精度最高的测量查询时间的工具。IO密集场景的测试中，慢查询日志带来的IO开销可忽略不计，实际CPU密集的场景中影响会大一些。

如果长期开启慢查询日志，注意要部署日志轮转（log rotation）工具。或只在需要收集负载样本的期间开启即可。

MySQL的通用日志一般只记录了到服务器的查询请求，不包含响应时间和执行计划等重要信息，所以很少用于分析、剖析服务器性能。

Percona对慢查询日志记录了更多有价值的信息。如查询执行计划、锁、IO活动等。可通过全局修改针对每个连接的long_query_time阈值，不用重置连接沲或持久连接的会话，停止连接的日志。

如果因权限问题无法在服务器上记录，可以使用以下方法：

* 通过pt-query-digest的--processlist选项，不断查看show full process list输出，记录查询第一次出现的时间和消失的时间。一些执行较快的查询无法捕获到。
* 通过tcpdump抓包，保存到磁盘，再利用pt-query-digest的--type=tcpdump选项解析并分析查询，该方法精确度较高，可捕获所有的查询。
* 通过mysqlproxy代理层脚本来记录所有查询。

#### 分析查询日志

pt-query-digest是慢日志分析最有力的工具。
V/M列提供了方差均值比的详细数据。离差指数高的查询对应的执行时间变化较大，这类查询通常值得优化。如果指定了--explain选项，输出结果会增加一列简要描述查询的执行计划。通过结合执行计划和V/M列，可以更容易地识别出性能低下的需要优化的查询。

尾部增加一行，用于显示最后17个占比较低，不值得单独显示的查询的统计数据。可以通过--limit和--outliers选项指定工具显示更多查询的详细信息。默认只会打印消耗前10位的查询，或者执行时间超过1秒阈值很多倍的查询。

直方图，可以对查询切片进行分析，多个峰值可能的原因。比如：查询条件传递了不同的值，而这些值的分布很不均衡，导致服务器选择了不同的索引；或查询缓存命中等。实际系统中，出现二个峰值的图很少见，查询越简单，执行计划越稳定。



### 3.3.2 剖析单条查询
#### 使用 show profile;
通过以下方式，
> set profiling=1;
> 
> select …
> 
>  ...
>  
> show profiles;
可以通过information_schema.profiling表取结果，并进行重新排序统计。

> set @query_id=1;
> 
> SELECT STATE,SUM(DURATION) AS TOtal_R,
> 
>   ROUND(
> 	  100 * SUM(DURATION) /
> 		(SELECT SUM(DURATION)
> 		FROM INFORMATION_SCHEMA.PROFILING
> 		WHERE QUERY_ID=@query_id
> 	  ),2) AS Pct_R,
> 	  
>   COUNT(*) AS Calls,
>   
>   SUM(DURATION) / COUNT(*) as "R/Call"
>   
> FROM INFORMATION_SCHEMA.PROFILING
> 
> WHERE QUERY_ID=@query_id
> 
> GROUP BY STATE
> 
> ORDER BY Total_R DESC;
> 

#### 使用 SHOW STATUS

> flush status;
> 
> show [global] status;
> 
> show status where Variable_name like 'Handler%' or Variable_name like 'Created%';

查看全局或会话级状态，一些计数器也是比较重要的。注意，show status本身会创建一个临时表，影响统计结果，show profiles创建至少2个，不同版本行为不同。

### select benchmark(1000000,1+1);


#### 使用慢查询日志
通过 tail -c +3214 /path/to/query.log |head -n100 直接跳转到日志的对应部分。

#### 使用Performance Schema
支持查询级别的剖析信息, 获得的裸数据过于复杂的底层，到目前为止还无法代替慢查询日志。
> select event_name, count_star, sum_timer_wait
> from events_waits_summary_global_by_event_name
> order by sum_timer_wait desc limit 5;


### 3.3.3 使用性能剖析

使用explain查询执行计划

## 3.4 诊断间歇性问题
诊断间歇性问题往往要花费很多时间，有时候甚至需要好几个月。有些人尝试用试错的方式来诊断，有时候通过随机地改变一些服务的设置来侥幸地找到问题。尽量不要用试错的方式，风险较大，因为结果可能变得更坏。如果一时未找到问题，可能是测量方式不正确，或者测量的点选择有误，或者使用的工具不适合。

已经解决的一些数据库问题的实际案例：
* 通过curl获取外部一个运行得很慢的外部服务来获取汇率报价数据。
* memcached缓存中一些重要条目过期，导致大量请求落到MySQL以重新生成缓存。
* DNS查询偶尔超时现象。
* 由于互斥锁争用，或内部删除查询缓存的算法效率太低的缘故，MySQL的查询缓存有时候会导致服务器有短暂的停顿。
* 当并发度超过某个阈值时，InnoDB的扩展性限制导致查询计划的优化需要很长的时间。

有些问题是数据库导致，有些不是，在有问题的地方观察资源使用情况，并尽可能地测量出数据，才能避免在没有问题的地方耗费精力。

### 3.4.1 单条查询还是服务器问题
首先要确定是单条查询的问题，还是服务器的问题。如果服务器上每一条查询都突然变慢了，又突然变好了，那么慢查询不一定是原因。如果服务器整体运行没有问题，只有某条查询偶尔变慢，就要注意这条特定的查询。

服务器问题非常常见，随着硬件性能的提升，16核或更多核服务器成了标配，mysql在SMP架构机器上的可扩展性限制也越来越显露出来。很多问题可通过升级到mysql新版本来解决。

如果问题不停周期性出现，那么可以在某次活动中观察到；可整夜收集数据，第二天来分析结果。大多数据情况下都可以通过如下三种技术来解决。

#### 使用show global status
观察一些“尖刺”或“凹陷”来发现。如: THreads_running, Threads_connected, Questions, Queries等。

> mysqladmin ext -i1|awk '
> /Queries/{q=$4-qp;qp=$4}
> /THreads_connected/{tc=$4}
> /Threads_running/{printf "%5d %5d %5d\n",q,tc,$4}'

运行几个小时或几天，然后将结果绘制成图形。
如果查询线程数上升，每秒的查询数下降，实践中2个原因可能性较大。一个是服务器内部遇到了瓶颈，新查询处理锁等待状态，使用服务器上出现大量排队问题。另一个原因是服务区突然遇到了大量查询请求的冲击，比如前端memcached突然失效导致的查询风暴。

#### 使用show process list
观察大量线程处于的状态。
> mysql -e 'SHOW PROCESSLIST\G' | grep State: | sort | uniq -c | sort -rn
> 
* Unauthenticated user 连接握手过程中的状态，在实践中，如果大量出现，检查skip-name-resolve是否有问题。
* freeing items 		innodb内部争用和脏块刷新所导致。
* end
* cleaning up
* logging slow query
* statistics 			查询优化阶段，如何确定表的关联顺序 
* Locked 				myisam表级锁或innodb的锁
* query cache lock 		更新查询缓存锁


通常还可以通过其它方法：

* information_schema.processlist表
* innotop 以较高的频繁刷新
*

#### 使用查询日志
需要开启慢查询日志，并在全局级设置long_query_time=0，要确认所有的连接都使用了新的设置。可能要重置所有连接以使用设置生效(Percona server不需要重置即可生效)。

呑吐量突然下降时，可归咎于吞吐量下降后完成的第一个查询（有时不一定是第一个）。
统计每秒查询数可用以下查询：
> awk '/^# Time:/{print $3, $4, c;c=0}/^# User/{c++}' slow-query.log
> 
> 030926 21:52:17 51
> 
> 030926 21:52:18 59
> …

#### insert 抖动问题
在InnoDB里，扩展表空间的操作是在语句执行过程中，由执行线程直接调用的。尤其是对于一些表每行比较大，则会出现每插入几条记录就需要扩展表空间。虽然有insert buffer和write ahead logging策略保证在执行线程中不直接操作表数据文件，但扩展表空间的操作会导致更新的tps出现瞬间低点，实际上整体TPS也受此影响。

mysql命令支持预扩展：
create database mydb;
create table mydb.t (c int) engine=InnoDB;
alter tablespace `mydb/t` set extent_size = 10000;




#### 理解发现的问题 (Making sense of the findings)
可视化的数据最具说服力。大量数据输出的结果可以选择用gnuplot或R进行图形绘制，绘图比excel快，也可对图上一些异常的地方进行缩放。
建议遇到问题时先使用show status或show process list，这两种方法开销很低。

### 3.4.2 捕获诊断数据
发现间歇性问题时，需要尽可能地多收集所有数据，而不只是问题出现时的数据。虽然这样会收集大师的诊断数据，但总比真正能够诊断问题的数据没有被收集到的情况要好。
在开始前，需要搞清楚两件事情：
* 一个可靠且空间里的"触发器"，也就是能区分什么时候问题出现的方法。
* 一个收集诊断数据的工具。

#### 诊断触发器
选择一下合适的阈值很重要，既要足够高，以确保正常时不会被触发，又不能太高，要确保问题发生时不会错过。在系统快要崩溃时才开始捕获数据，就很难诊断最初的根本原因。如果可能，在问题还是澡澡细流时就会始捕获数据，而不要等到波涛汹涌时才开始。

比如，Thread_connected偶尔出现非常高的尖峰值，在几分钟时间内会从100冲到5000或更高，如果正常时阈值不超过150，将阈值设置为200~300会更好。Thread_running正常情况下并发度不超过10，但阈值设置为10并不是一个好主意，很可能会导致很多误报，即使设置为15也还是不够，可能会有很多正常的波动到这个范围。建议设置为20。

我们需要一种工具来监控服务器，当达到触发条件时能收集数据。Percona Tookit中的pt-stalk就是为这种情况设计的，有很多特性，如果遇到这类问题，就会明白这些特性的必要性了。pt-stalk可以配置需要监控的变量、阈值、检查频率等，它依赖一个工具执行真正收集工作。

> mysql -e 'show processlist\G' | grep -c 'State: freeing items'


#### 需要收集什么样的数据
现在已经开启了诊断触发器，可以开启一些进程来收集数据了。但需要收集什么样的数据呢？系统状态、CPU利用率、磁盘使用率、可用空间、ps采样


#### 

### 3.4.3 一个诊断案例


## 3.5 其它剖析工具

### 3.5.1 使用 USER_STATISTICS表

### 3.5.2 使用 strace
查看每个进程在做什么
> for i in /proc/$(pidof mysqld)/task/*; do timeout -s INT 4 strace -p $(basename $i); done




